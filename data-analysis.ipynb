{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visual-taxonomy-small\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from pathlib import Path\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "import ssl\n",
    "import urllib.request\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "SMALL_DATASET = True\n",
    "data_path = Path(f'visual-taxonomy-{\"small\" if SMALL_DATASET==True else \"\"}/')\n",
    "test_image_path = data_path / 'test_images'\n",
    "train_image_path = data_path / 'train_images'\n",
    "print(data_path)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id         len\n",
      "count    800.000000  800.000000\n",
      "mean   35923.855000    8.760000\n",
      "std    20322.458313    1.597056\n",
      "min      319.000000    5.000000\n",
      "25%    18224.750000    8.000000\n",
      "50%    37700.000000   10.000000\n",
      "75%    53628.500000   10.000000\n",
      "max    70376.000000   10.000000\n",
      "                 id\n",
      "count    200.000000\n",
      "mean   14470.730000\n",
      "std     9026.003275\n",
      "min       86.000000\n",
      "25%     6983.750000\n",
      "50%    13839.500000\n",
      "75%    21583.500000\n",
      "max    30461.000000\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(data_path / 'train.csv')\n",
    "df_test = pd.read_csv(data_path / 'test.csv')\n",
    "print(df_train.describe())\n",
    "print(df_test.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id             Category  len         attr_1         attr_2      attr_3  \\\n",
      "0  15996               Sarees   10            NaN            NaN         NaN   \n",
      "1  62298  Women Tops & Tunics   10         maroon        regular     regular   \n",
      "2  22725               Sarees   10  same as saree  temple border  big border   \n",
      "3  39408        Women Tshirts    8           pink        regular     regular   \n",
      "4  41847        Women Tshirts    8        default        regular     regular   \n",
      "\n",
      "      attr_4       attr_5         attr_6           attr_7         attr_8  \\\n",
      "0        NaN          NaN            NaN       zari woven            NaN   \n",
      "1   stylised       casual          solid            solid  short sleeves   \n",
      "2  navy blue        daily       jacquard       zari woven          solid   \n",
      "3    printed  funky print  short sleeves  regular sleeves            NaN   \n",
      "4    printed   typography   long sleeves  regular sleeves            NaN   \n",
      "\n",
      "         attr_9 attr_10  \n",
      "0           NaN     NaN  \n",
      "1  puff sleeves     NaN  \n",
      "2         solid     yes  \n",
      "3           NaN     NaN  \n",
      "4           NaN     NaN  \n",
      "---\n",
      "      id             Category\n",
      "0  14051        Women Tshirts\n",
      "1  16851        Women Tshirts\n",
      "2  29093  Women Tops & Tunics\n",
      "3   3005          Men Tshirts\n",
      "4   7703               Sarees\n"
     ]
    }
   ],
   "source": [
    "print(df_train.head())\n",
    "print('---')\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'000000.jpg' in os.listdir(train_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_range = range(len(df_train))\n",
    "test_range = range(len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SMALL_DATASET == False:\n",
    "    plt.figure(figsize=(30, 30))\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            idx = random.randint(0, len(df_train))\n",
    "            img = Image.open(train_image_path / f'{idx:06d}.jpg')\n",
    "            plt.subplot(4, 4, 4 * i + j + 1)\n",
    "\n",
    "            plt.imshow(img)\n",
    "            plt.title(df_train.loc[idx, 'Category'])\n",
    "        \n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "from tempfile import TemporaryDirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SMALL_DATASET == False:\n",
    "    num = 560\n",
    "    img = Image.open(train_image_path / f'{num:06d}.jpg')\n",
    "    img_1 = data_transforms['train'](img)\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(img_1.permute(1, 2, 0))\n",
    "    plt.show()\n",
    "    print(df_train.loc[num, 'Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Category'].value_counts()\n",
    "df_train.fillna('None', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([15996, 62298, 22725, 39408, 41847, 55370, 24305, 55732,  4647,\n",
      "       60868, 29390, 61269, 62642, 26950, 11350, 53620, 46455, 23663,\n",
      "       24452, 69159, 48490, 12380, 28621, 42347, 41830, 29304, 63461,\n",
      "       31661, 66162, 46049, 51052, 57798, 69725, 66461, 36856, 33033,\n",
      "       43253, 18487, 54289, 68217, 28528, 37298, 32188, 48082, 60510,\n",
      "       38759, 49055, 69401, 63901, 45394, 58947, 64612, 35981, 16392,\n",
      "        9574, 14076, 37302, 28051, 40268, 34551, 38375, 50213, 17945,\n",
      "       53692, 40921, 61294, 34695, 60662, 22994, 28245, 64559, 39328,\n",
      "       68042, 44829,  6942, 54992,  7141, 56277, 52150, 54311,  4998,\n",
      "       69257, 29811, 16160, 29900, 57738, 67047, 60724, 55931, 62916,\n",
      "        3503,  3244, 15657, 54854,  5019, 66098, 39581, 42698, 18293,\n",
      "       49389, 42616, 43250, 13727,  8441,  2521, 13041, 13174,  7257,\n",
      "       32677, 26302, 61385, 58794, 59389, 23582, 12791, 50949, 58444,\n",
      "       42251,   449, 25577, 17175, 61725, 22581,  4764, 25538, 15621,\n",
      "       33636, 27325, 29319, 13790,  4940,  1955, 11720,  5611, 68351,\n",
      "       19717, 10591, 14922, 32801, 55888, 69894,  9107, 14125, 43366,\n",
      "        1044, 63741, 54062, 67229, 59655, 34291, 48529, 69041, 36793,\n",
      "       17260,  4467, 38313, 27872, 59860, 60528, 31178, 30503, 48658,\n",
      "       18401, 46923, 35120, 29699, 46086, 46302, 61500, 55752, 64372,\n",
      "        5086, 30302, 33239, 21157, 20447, 21845, 26476, 28171, 35992,\n",
      "        4737, 66931,   333, 12554, 30438, 29338, 25211, 38869, 38675,\n",
      "       35267, 18977, 57115, 25118, 42468, 25140, 12273, 38316,   900,\n",
      "       48232, 55457, 33881,  2782, 18851, 17349, 30498, 39288, 27837,\n",
      "       16144, 12919, 51810, 65835, 66400, 10350, 50212, 42152, 41280,\n",
      "       68055,  7335, 49390, 54147, 37164, 65330,  7584,   415, 57571,\n",
      "       33867, 24759, 69205, 39380, 42299, 57844, 38993, 69513, 40727,\n",
      "       33166, 39667, 61432,  7677, 42328, 55421, 65031, 17012, 54896,\n",
      "        8180,  8970, 58465, 41206,  6799,  9958, 64829, 26934, 33962,\n",
      "       23638, 57227, 62038, 51973, 70308, 46136, 12187, 25953, 33532,\n",
      "       39740, 69933, 59469, 34550, 50254, 55763, 59409, 12350, 16020,\n",
      "       38359, 10407, 59760, 49052, 15444, 31575, 49583, 42883, 65963,\n",
      "       37479, 64778, 23856, 38231, 38212, 51380, 33973, 51409, 46315,\n",
      "       43649, 61961, 20182, 33939, 54917, 62553,  4898, 62498, 37802,\n",
      "       42660, 56549, 54321, 34686, 53210, 33852, 39861, 53030, 49344,\n",
      "       55594, 54408, 46173, 23677, 32378, 18203, 16309, 26894, 10031,\n",
      "       40612, 68139,  8231, 52117,  1641, 13257, 13266, 67571, 16267,\n",
      "       16300,   585, 56498,  5425, 61990,  2467, 46128, 41916, 18423,\n",
      "       49748, 13768, 23958, 47583, 20595, 19855, 65028, 22789, 55169,\n",
      "       32104, 41548, 51191, 56963, 70260, 26387, 45847,  6827, 60146,\n",
      "       27675, 35502, 38552, 53288, 57409, 57802,  4283, 17582, 70376,\n",
      "       38105, 23722, 36746,  9045, 35368, 69349, 59470, 48818, 43804,\n",
      "       18689, 14519, 10548, 19069, 12611,  3788, 47822,  7058, 26460,\n",
      "       67973, 61970, 24974, 69896, 53654, 14161,  1227,  2678, 40967,\n",
      "       38787, 67101,  3235, 34224, 46390, 12061, 35762, 56066, 30866,\n",
      "       63142, 32872, 69509, 35224,  6568, 46448, 14577, 50154, 46393,\n",
      "       14884, 41973,  9507, 12425,  3355,  1623,  5854, 55065,  8278,\n",
      "       24357, 19681, 45900, 57430, 19733, 44622, 49197,  2088, 56510,\n",
      "       48340, 19311, 30147, 20248, 43787, 62058, 70363, 51000,  8456,\n",
      "       43717, 42282,  5982,  5117, 57810,  4656, 46002,  1331, 45667,\n",
      "        8485, 36880, 29029, 44106, 57993, 23013, 49095, 64200, 55659,\n",
      "       13884, 49098, 41643, 69246, 50391, 56715, 54960,  5255,  3392,\n",
      "       62140, 50366, 22410, 48863, 36487,  1680, 14871, 63367, 19726,\n",
      "       47182, 67325, 35795, 25590, 57642, 44416, 52815, 38230, 65988,\n",
      "       45025,  6909, 17810, 34067, 35752, 29455, 51854, 66620, 15761,\n",
      "        7170, 51570, 50445,  5754, 40060, 10996,  6832, 58920,  4071,\n",
      "       63133, 47308, 31879, 28838, 32901, 27274, 19688, 14704, 42087,\n",
      "        2983, 68029, 13406, 64025,  8968, 37685, 36001, 27765, 39568,\n",
      "        1999, 24992, 58873,  3006, 15003, 10840, 20318, 56615,  6992,\n",
      "       23039, 46853,  5897, 70168, 65711, 43861, 36887, 53069, 52701,\n",
      "       31525, 37861, 28160, 28440, 51999, 46382, 50004, 48675, 54965,\n",
      "       40715,  1737, 18353, 25109, 16496, 43176, 11549, 11885,  5853,\n",
      "       70144, 56151, 36265, 50347, 60885, 24890, 20374, 22393, 32815,\n",
      "       66631,  5410, 56102, 43873, 21618, 38849, 55521, 69190, 35357,\n",
      "       21214, 27321, 25214, 47715, 44667, 17475, 54373, 55389, 43888,\n",
      "       26962, 69303,  4562, 12636, 46187, 45793, 28975,  1058, 21118,\n",
      "       57913, 14968, 48901, 38264, 58498, 54052, 20315,  6622, 50979,\n",
      "       37414, 65000, 16135,  5178, 31197, 68803, 15307, 47005,  6877,\n",
      "       36563, 61094,   319, 34520, 50395, 19114, 65958, 10574, 41732,\n",
      "       64471,  4646,  1379, 59967, 24302,  5431,  5077, 67130, 26686,\n",
      "       30747, 39449,  4247, 18594, 60231, 55761, 60404,  3561, 14714,\n",
      "       40886, 47529, 46635, 55276, 22665,  6521, 37545, 20455, 36015,\n",
      "       44898, 66603, 47688, 59825, 37931, 59123, 63154, 68043, 44895,\n",
      "       69831, 14191, 38792, 42257, 48711, 65441, 39863, 39728, 38124,\n",
      "       63160,  1803, 40257, 45075, 18862, 10117, 45682, 54105, 34710,\n",
      "       50337, 64183, 11974, 18232, 54007,  2737, 61900, 38269, 12995,\n",
      "        8018, 30520, 23333, 26087, 11568, 44730, 62757, 37715, 53685,\n",
      "       38487, 23916, 38717, 10156, 43944, 35388,   716, 19708, 38029,\n",
      "       14086, 17238, 56363, 46996,  4877, 61202, 64848, 66277, 62928,\n",
      "       29252, 66840, 40963,  2265, 25195, 50591,  2416, 31513, 19439,\n",
      "       31918, 51059, 20719, 68509,  8075, 52223, 39580, 28616, 49053,\n",
      "        9756, 43429, 29853,  4801, 17867,  7763, 67316, 41628, 36795,\n",
      "       14040, 12623, 35073,  4477, 55564, 32614, 51703,  6282, 14667,\n",
      "       23231,   786, 32283,   712, 40892, 37762, 10421, 56802, 62099,\n",
      "        2277, 53551, 16296, 47013, 32406, 32029, 55664, 65986, 27652,\n",
      "       45816, 12626, 26726,  3606, 27579, 39975, 11435, 67646, 62959,\n",
      "       58927, 65519, 12186, 18433, 64667, 40418, 19136, 22459, 44986,\n",
      "        3597, 13660, 21115, 48037, 11569, 15261, 64157, 11497, 23413,\n",
      "       56912,  3915, 46544, 10603, 54877, 42802, 49375, 27929, 70083,\n",
      "       65530]), array(['Sarees', 'Women Tops & Tunics', 'Women Tshirts', 'Men Tshirts',\n",
      "       'Kurtis'], dtype=object), array([10,  8,  5,  9]), array(['None', 'maroon', 'same as saree', 'pink', 'default', 'black',\n",
      "       'red', 'multicolor', 'white', 'blue', 'yellow', 'same as border',\n",
      "       'peach', 'green', 'navy blue', 'solid'], dtype=object), array(['None', 'regular', 'temple border', 'zari', 'boxy', 'polo',\n",
      "       'fitted', 'a-line', 'woven design', 'no border', 'loose', 'solid',\n",
      "       'default', 'round', 'straight'], dtype=object), array(['None', 'regular', 'big border', 'small border', 'crop', 'solid',\n",
      "       'calf length', 'no border', 'knee length', 'long', 'printed'],\n",
      "      dtype=object), array(['None', 'stylised', 'navy blue', 'printed', 'cream', 'round neck',\n",
      "       'solid', 'daily', 'multicolor', 'default', 'high', 'square neck',\n",
      "       'sweetheart neck', 'white', 'v-neck', 'typography', 'green',\n",
      "       'party', 'pink', 'yellow'], dtype=object), array(['None', 'casual', 'daily', 'funky print', 'typography', 'party',\n",
      "       'short sleeves', 'net', 'graphic', 'traditional', 'quirky',\n",
      "       'solid', 'default', 'wedding', 'long sleeves'], dtype=object), array(['None', 'solid', 'jacquard', 'short sleeves', 'long sleeves',\n",
      "       'printed', 'default', 'tassels and latkans'], dtype=object), array(['zari woven', 'solid', 'regular sleeves', 'default', 'None',\n",
      "       'quirky', 'typography', 'woven design', 'graphic', 'floral',\n",
      "       'cuffed sleeves', 'same as saree'], dtype=object), array(['None', 'short sleeves', 'solid', 'zari woven', 'sleeveless',\n",
      "       'three-quarter sleeves', 'default', 'long sleeves', 'woven design',\n",
      "       'printed', 'applique'], dtype=object), array(['None', 'puff sleeves', 'solid', 'floral', 'regular sleeves',\n",
      "       'sleeveless', 'regular', 'default', 'peacock', 'checked',\n",
      "       'elephant', 'ethnic motif', 'botanical'], dtype=object), array(['None', 'yes', 'waist tie-ups', 'no', 'knitted', 'tie-ups',\n",
      "       'default', 'ruffles', 'applique'], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "values = [df_train[col].unique() for col in df_train.columns]\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sarees', 'Women Tops & Tunics', 'Women Tshirts', 'Men Tshirts',\n",
       "       'Kurtis'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list(values[1]).index('Men Tshirts')\n",
    "values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_attributes_to_tensor(df):\n",
    "    # df = df.fillna('None')\n",
    "    attr_list = [list(values[i]).index(df.iloc[i]) for i in range(1, len(df))]\n",
    "    return torch.tensor(attr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               15996\n",
       "Category        Sarees\n",
       "len                 10\n",
       "attr_1            None\n",
       "attr_2            None\n",
       "attr_3            None\n",
       "attr_4            None\n",
       "attr_5            None\n",
       "attr_6            None\n",
       "attr_7      zari woven\n",
       "attr_8            None\n",
       "attr_9            None\n",
       "attr_10           None\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_attributes_to_tensor(df_train.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, \n",
    "                root_dir: str,\n",
    "                root_csv: str,\n",
    "                file_numbers: [i for i in range(0, 70000)],\n",
    "                transform=None):\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.root_csv = root_csv\n",
    "        self.transform = transform\n",
    "        self.file_numbers = file_numbers \n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.root_csv)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_number = self.file_numbers[idx]\n",
    "        img = Image.open(self.root_dir / f'{file_number:06d}.jpg')\n",
    "        transformed_img = self.transform(img)\n",
    "\n",
    "        attributes = convert_attributes_to_tensor(self.root_csv.loc[idx])\n",
    "\n",
    "        return transformed_img, attributes[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41966, 26475, 48830, 62057, 44912, 28701, 42722, 3683, 4784, 55206, 69926, 65503, 2879, 30656, 50534, 27187, 43454, 54809, 18929, 29682, 65132, 43117, 41577, 24352, 1242, 4842, 55609, 27224, 25688, 15118, 56869, 22389, 46106, 7251, 2095, 24907, 58808, 24095, 25031, 50405, 68444, 39358, 40633, 8425, 64787, 56343, 51931, 22300, 7580, 5956, 40763, 35859, 61126, 59603, 69777, 65691, 49639, 8344, 36904, 22406, 37091, 63992, 45119, 58433, 21171, 4821, 24694, 24293, 51443, 17811, 42018, 3236, 6575, 956, 68478, 41112, 23500, 32700, 69970, 13933, 56105, 13477, 67396, 56106, 65296, 30728, 64069, 41212, 30948, 33340, 7183, 32794, 14968, 17401, 50905, 64591, 3475, 34236, 62159, 33494, 26690, 25774, 29793, 45318, 61627, 54008, 59918, 65582, 27303, 38835, 23040, 8490, 12013, 47656, 28937, 47832, 1806, 54299, 8880, 14075, 8801, 37927, 22645, 58625, 25185, 31760, 44168, 22458, 5739, 1858, 10728, 16993, 37602, 19047, 58943, 37840, 11994, 21370, 29633, 18926, 31639, 40218, 37267, 42975, 17764, 6484, 68413, 22633, 44096, 43366, 33049, 60691, 50175, 52486, 64402, 33944, 22204, 37531, 13826, 29253, 34844, 2252, 56462, 1253, 59548, 63630, 9383, 40151, 27856, 34817, 23836, 10307, 22793, 13089, 39208, 4578, 58287, 21993, 19374, 54115, 679, 64401, 5137, 53354, 23252, 31787, 42227, 6161, 10380, 23641, 33940, 26843, 65986, 20129, 29181, 61298, 63871, 52521, 37735, 8061, 58490, 57478, 4678, 56072, 42535, 18995, 66755, 35072, 63351, 31544, 7896, 63533, 60793, 45633, 14509, 2040, 53555, 11321, 64624, 31469, 62006, 31448, 2263, 50281, 11795, 36, 15744, 20690, 36353, 36390, 6924, 52997, 36958, 2368, 28835, 66104, 4668, 35885, 46402, 42055, 33343, 47366, 9929, 44632, 34689, 67190, 7335, 11448, 4941, 40018, 21524, 45076, 34893, 32983, 64548, 60689, 941, 24604, 56604, 57252, 14204, 45874, 53092, 40947, 52592, 4732, 63597, 14982, 61163, 42971, 62125, 33580, 4657, 38570, 18305, 32533, 33737, 41439, 65577, 14889, 46156, 69834, 6164, 11231, 68717, 22379, 16093, 46106, 24887, 33960, 33848, 39339, 19486, 28956, 1761, 35135, 53559, 8406, 50303, 20897, 39107, 41662, 1424, 28241, 9540, 61434, 44922, 12094, 30063, 28335, 12947, 25, 38093, 55149, 27040, 32543, 43986, 21387, 35387, 66204, 67132, 66367, 12438, 47344, 35211, 48226, 60743, 7349, 18347, 14569, 46186, 2973, 31628, 1874, 14114, 54632, 48067, 41156, 57343, 4974, 2028, 63348, 52582, 58090, 6674, 40644, 43714, 33664, 21998, 29132, 10902, 66559, 67431, 24434, 33669, 8213, 44478, 54355, 57264, 55825, 27546, 10463, 43535, 13764, 21685, 53444, 45724, 51252, 3880, 66918, 5557, 66834, 65421, 32689, 24925, 37541, 60193, 15422, 37484, 829, 11134, 65291, 622, 17587, 12234, 44663, 14817, 3153, 58536, 29387, 63975, 15817, 55088, 66541, 14289, 23726, 53854, 6533, 40192, 52328, 14909, 52178, 2219, 13430, 65766, 29170, 42528, 3800, 4681, 54018, 61462, 43022, 30873, 45308, 48374, 31464, 5894, 30058, 42111, 36647, 9723, 61966, 36087, 12767, 2043, 32266, 22742, 48070, 30405, 20325, 7038, 66468, 39977, 2636, 56776, 17453, 36879, 50623, 50152, 16699, 26124, 63885, 60109, 7488, 62709, 40919, 61780, 21745, 32546, 52091, 25100, 29684, 53574, 67143, 36368, 39821, 27431, 1008, 768, 25514, 33758, 12494, 68642, 58726, 33713, 1966, 50175, 38501, 4566, 45698, 10233, 1151, 35185, 24309, 52206, 38613, 29406, 67008, 9120, 48088, 24338, 54914, 40605, 63389, 54892, 32389, 8540, 54509, 61081, 4958, 35002, 9868, 67089, 65512, 57336, 42744, 35681, 59032, 27268, 62868, 47740, 29485, 18104, 52931, 33822, 69370, 64689, 37113, 29916, 4156, 27874, 34394, 23960, 13766, 41612, 46919, 12587, 40012, 53170, 62939, 25963, 55212, 28352, 21837, 25024, 58675, 29758, 34992, 32669, 42004, 55365, 56616, 34898, 39694, 69214, 25656, 68543, 20628, 24133, 51205, 57745, 18137, 54200, 36863, 21677, 1638, 15566, 59279, 20512, 8922, 25368, 45798, 29527, 46180, 56427, 28054, 5984, 21877, 59987, 47949, 29269, 53122, 24709, 68032, 12026, 52848, 1016, 32689, 55765, 16495, 19352, 36, 561, 32604, 42423, 45121, 48760, 15862, 55347, 19020, 50450, 45315, 17450, 43084, 59056, 59683, 11845, 28381, 27374, 46775, 28584, 51743, 21257, 37639, 18436, 37874, 43213, 63536, 54456, 45430, 33925, 46198, 47348, 37033, 10990, 20860, 10741, 68666, 13772, 20765, 53790, 22779, 27284, 50533, 31261, 23735, 21395, 65979, 33212, 28430, 30513, 14174, 52314, 59341, 23883, 16135, 68901, 48538, 59357, 36371, 32197, 67818, 62425, 359, 37111, 53627, 30517, 40704, 7754, 20018, 57451, 51442, 57658, 59071, 65799, 61291, 36724, 7133, 65285, 7164, 66993, 29244, 4489, 67822, 38758, 66086, 38874, 15122, 42145, 37582, 4961, 13094, 41303, 40192, 12052, 53834, 20254, 66680, 922, 55289, 67099, 28973, 11265, 401, 25861, 61888, 5280, 50723, 17642, 29094, 9223, 42199, 35393, 58003, 30849, 67661, 503, 16111, 9156, 13833, 41328, 44419, 20691, 7981, 56947, 49748, 57135, 24592, 6948, 58400, 44122, 41138, 52921, 42058, 52547, 35618, 17299, 21840, 58680, 68747, 60982, 39139, 5700, 10478, 8624, 37012, 69135, 36727, 60626, 40222, 27296, 23938, 5332, 60527, 31912, 26440, 37851, 33588, 19513, 33256, 48260, 20340, 24016, 6901, 934, 67734, 47137, 69640, 67889, 34486, 33184, 12848, 15844, 13319, 2169, 53642, 59559, 45112, 33807, 33213, 24849, 32152, 45956, 13875, 21924, 7948, 17245, 61879, 8323, 63269, 32445, 10645, 4565, 43985, 69119, 47665, 21572, 66520, 14673, 70039, 28570, 48769, 32386, 23710, 29404, 10362, 31980, 11000, 18436, 20406, 66792, 34747, 10264, 17499, 8277, 6871, 70058, 49986, 1398, 28259, 60435, 44696, 12126, 25139, 44383, 66908, 15947, 24864, 1427, 3909]\n"
     ]
    }
   ],
   "source": [
    "with open(\"rand_list_train.json\", \"r\") as f:\n",
    "    rand_list_train = json.load(f)\n",
    "\n",
    "print(rand_list_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21156, 23991, 12552, 4822, 28126, 29747, 922, 24626, 13922, 19260, 1178, 20791, 5581, 22880, 1600, 14282, 16991, 21358, 22821, 7758, 12155, 23848, 26181, 24837, 17091, 18375, 23837, 14808, 29703, 3632, 29935, 21004, 6693, 10948, 26840, 13848, 4726, 14589, 10590, 25854, 2520, 8870, 11839, 1600, 21570, 21564, 21705, 11099, 8244, 29501, 13311, 15701, 19108, 15094, 15976, 4167, 21301, 18421, 22634, 6270, 20342, 25554, 26263, 10278, 22410, 25822, 26895, 10143, 26454, 20828, 12434, 4471, 15262, 14545, 9846, 9661, 9223, 25623, 19862, 11147, 10353, 4023, 19837, 25896, 16814, 8357, 28545, 947, 22328, 18761, 27218, 797, 5564, 13385, 7595, 17877, 4835, 29630, 6276, 26385, 27139, 24871, 25685, 23355, 28228, 10965, 9048, 13846, 3608, 29563, 26516, 16714, 18221, 20638, 20634, 6520, 12724, 6875, 1423, 3387, 24019, 6590, 21642, 18933, 21671, 22751, 10661, 25598, 27312, 18281, 1230, 22341, 17561, 17144, 28037, 675, 5225, 23752, 5056, 6221, 13713, 13593, 20021, 28249, 11158, 28346, 553, 29085, 22652, 215, 3962, 22383, 10556, 10227, 10087, 28356, 13172, 20026, 14453, 19038, 16496, 23550, 1935, 3747, 10603, 27917, 12097, 26588, 22194, 17876, 4509, 13222, 13815, 18540, 13221, 21981, 17307, 6047, 10351, 3232, 12551, 5607, 20236, 17057, 8181, 14858, 26718, 17307, 27186, 14534, 10232, 29187, 23140, 3616, 19699, 17973, 9209, 4831, 8538, 2852]\n"
     ]
    }
   ],
   "source": [
    "with open(\"rand_list_test.json\", \"r\") as f:\n",
    "    rand_list_test = json.load(f)\n",
    "\n",
    "print(rand_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_image_path, df_train, rand_list_train, data_transforms['train'])\n",
    "test_dataset = CustomDataset(test_image_path, df_test, rand_list_test, data_transforms['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.3130, -1.3130, -1.2788,  ...,  1.5982,  1.6153,  1.6324],\n",
       "          [-1.3302, -1.3130, -1.2788,  ...,  1.5810,  1.5982,  1.6153],\n",
       "          [-1.3302, -1.3302, -1.2959,  ...,  1.5468,  1.5982,  1.5982],\n",
       "          ...,\n",
       "          [ 1.7694,  1.7694,  1.7694,  ..., -1.4672, -1.4672, -1.4843],\n",
       "          [ 1.7694,  1.7694,  1.7694,  ..., -1.4843, -1.5357, -1.5357],\n",
       "          [ 1.7694,  1.7694,  1.7694,  ..., -1.4843, -1.5185, -1.5185]],\n",
       " \n",
       "         [[-2.0357, -2.0357, -2.0357,  ...,  1.7458,  1.7108,  1.7458],\n",
       "          [-2.0357, -2.0357, -2.0357,  ...,  1.7108,  1.7108,  1.7108],\n",
       "          [-2.0357, -2.0357, -2.0357,  ...,  1.6933,  1.6933,  1.6933],\n",
       "          ...,\n",
       "          [ 1.7808,  1.7808,  1.7808,  ..., -2.0357, -2.0357, -2.0357],\n",
       "          [ 1.7808,  1.7808,  1.7808,  ..., -2.0357, -2.0357, -2.0357],\n",
       "          [ 1.7808,  1.7808,  1.7808,  ..., -2.0357, -2.0357, -2.0357]],\n",
       " \n",
       "         [[-1.8044, -1.8044, -1.8044,  ...,  1.9080,  1.9080,  1.9080],\n",
       "          [-1.8044, -1.8044, -1.8044,  ...,  1.9080,  1.8731,  1.8557],\n",
       "          [-1.8044, -1.8044, -1.8044,  ...,  1.8731,  1.8383,  1.8383],\n",
       "          ...,\n",
       "          [ 2.0474,  2.0474,  2.0474,  ..., -1.8044, -1.8044, -1.8044],\n",
       "          [ 2.0474,  2.0474,  2.0474,  ..., -1.8044, -1.8044, -1.8044],\n",
       "          [ 2.0474,  2.0474,  2.0474,  ..., -1.8044, -1.8044, -1.8044]]]),\n",
       " tensor(0))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SMALL_DATASET == False:\n",
    "    image, label = train_dataset[100]\n",
    "    plt.imshow(image.permute(1, 2, 0))\n",
    "    print(label)\n",
    "    print(values[1][label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
       "           [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
       "           [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
       "           ...,\n",
       "           [ 2.2489,  2.2489,  2.2489,  ...,  0.3309,  0.1426,  1.0673],\n",
       "           [ 2.2489,  2.2489,  2.2489,  ...,  0.2796,  0.1768,  0.2111],\n",
       "           [ 2.2489,  2.2489,  2.2489,  ...,  0.1768,  0.1768, -0.1143]],\n",
       " \n",
       "          [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
       "           [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
       "           [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
       "           ...,\n",
       "           [ 2.4286,  2.4286,  2.4286,  ..., -1.9832, -1.9132,  0.1527],\n",
       "           [ 2.4286,  2.4286,  2.4286,  ..., -1.8606, -1.7556, -1.0378],\n",
       "           [ 2.4286,  2.4286,  2.4286,  ..., -1.8782, -1.7556, -1.7906]],\n",
       " \n",
       "          [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
       "           [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
       "           [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
       "           ...,\n",
       "           [ 2.6400,  2.6400,  2.6400,  ..., -1.8044, -1.7870,  0.2348],\n",
       "           [ 2.6400,  2.6400,  2.6400,  ..., -1.8044, -1.8044, -1.0027],\n",
       "           [ 2.6400,  2.6400,  2.6400,  ..., -1.8044, -1.8044, -1.8044]]],\n",
       " \n",
       " \n",
       "         [[[ 2.2489,  2.2489,  2.2489,  ...,  2.0092,  2.0092,  2.0092],\n",
       "           [ 2.2489,  2.2489,  2.2489,  ...,  2.0092,  1.9920,  1.9920],\n",
       "           [ 2.2489,  2.2489,  2.2489,  ...,  2.0092,  1.9920,  1.9920],\n",
       "           ...,\n",
       "           [ 2.2489,  2.2489,  2.2318,  ...,  1.8893,  1.8893,  1.8893],\n",
       "           [ 2.2489,  2.2489,  2.1975,  ...,  1.8893,  1.8893,  1.8893],\n",
       "           [ 2.2489,  2.2489,  2.1804,  ...,  1.8893,  1.8893,  1.8893]],\n",
       " \n",
       "          [[ 2.2360,  2.2360,  2.2360,  ...,  1.3957,  1.3957,  1.3957],\n",
       "           [ 2.2360,  2.2360,  2.2535,  ...,  1.3957,  1.3782,  1.3782],\n",
       "           [ 2.2360,  2.2360,  2.2535,  ...,  1.3957,  1.3782,  1.3782],\n",
       "           ...,\n",
       "           [ 2.1835,  2.1835,  2.1310,  ...,  1.8859,  1.8859,  1.8859],\n",
       "           [ 2.1485,  2.1310,  2.0959,  ...,  1.8859,  1.8859,  1.8859],\n",
       "           [ 2.1134,  2.0959,  2.0959,  ...,  1.8859,  1.8859,  1.8859]],\n",
       " \n",
       "          [[ 2.6400,  2.6400,  2.6400,  ...,  2.0648,  2.0648,  2.0648],\n",
       "           [ 2.6400,  2.6400,  2.6400,  ...,  2.0648,  2.0648,  2.0648],\n",
       "           [ 2.6400,  2.6400,  2.6400,  ...,  2.0648,  2.0648,  2.0648],\n",
       "           ...,\n",
       "           [ 1.7511,  1.7337,  1.7685,  ...,  2.5006,  2.5006,  2.5006],\n",
       "           [ 1.7163,  1.6640,  1.7511,  ...,  2.5006,  2.5006,  2.5006],\n",
       "           [ 1.6465,  1.6291,  1.6988,  ...,  2.5006,  2.5006,  2.5006]]],\n",
       " \n",
       " \n",
       "         [[[-1.8610, -1.9980, -1.9980,  ..., -0.0801, -0.1828, -0.3198],\n",
       "           [-1.8268, -1.9467, -1.9638,  ..., -0.0629, -0.3027, -0.5767],\n",
       "           [-1.8439, -1.6898, -1.8268,  ..., -0.1314, -0.2342, -0.4226],\n",
       "           ...,\n",
       "           [ 1.5810,  1.5125,  1.5297,  ...,  1.0844,  0.7248,  1.0159],\n",
       "           [ 1.5639,  1.5982,  1.4954,  ...,  1.2728,  0.9646,  1.0673],\n",
       "           [ 1.5297,  1.5468,  1.5125,  ...,  1.0844,  1.1872,  1.2557]],\n",
       " \n",
       "          [[-1.9832, -2.0182, -2.0182,  ..., -0.5826, -0.6527, -0.7577],\n",
       "           [-1.9657, -2.0007, -2.0007,  ..., -0.5301, -0.7577, -1.0028],\n",
       "           [-1.9832, -1.8957, -1.9832,  ..., -0.5826, -0.6702, -0.8803],\n",
       "           ...,\n",
       "           [ 1.6408,  1.5532,  1.5357,  ...,  0.9930,  0.6254,  0.9055],\n",
       "           [ 1.5882,  1.6232,  1.5007,  ...,  1.2031,  0.8354,  0.9405],\n",
       "           [ 1.5182,  1.5532,  1.5007,  ...,  1.0280,  1.0980,  1.1681]],\n",
       " \n",
       "          [[-1.8044, -1.8044, -1.8044,  ..., -1.0376, -1.1421, -1.3164],\n",
       "           [-1.8044, -1.8044, -1.8044,  ..., -1.0027, -1.2641, -1.5604],\n",
       "           [-1.8044, -1.8044, -1.8044,  ..., -1.1247, -1.2293, -1.4907],\n",
       "           ...,\n",
       "           [ 1.6117,  1.5071,  1.5071,  ...,  1.2108,  0.8448,  1.1062],\n",
       "           [ 1.5245,  1.5245,  1.4200,  ...,  1.3851,  1.0365,  1.1237],\n",
       "           [ 1.4200,  1.4200,  1.3677,  ...,  1.1934,  1.2631,  1.2980]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 1.4783,  1.5125,  1.5468,  ...,  1.5639,  1.5297,  1.5639],\n",
       "           [ 1.4783,  1.4954,  1.5468,  ...,  1.5810,  1.5639,  1.5982],\n",
       "           [ 1.5125,  1.4954,  1.4954,  ...,  1.5810,  1.5810,  1.6153],\n",
       "           ...,\n",
       "           [ 1.3070,  1.3242,  1.3242,  ...,  1.3413,  0.8961,  0.8276],\n",
       "           [ 1.3242,  1.3070,  1.3070,  ...,  0.5364,  0.9474,  1.1700],\n",
       "           [ 1.3070,  1.3070,  1.2557,  ...,  0.1597,  1.1872,  1.1700]],\n",
       " \n",
       "          [[ 1.4307,  1.4657,  1.5007,  ...,  1.6408,  1.6057,  1.6408],\n",
       "           [ 1.4307,  1.4657,  1.5007,  ...,  1.6408,  1.6408,  1.6583],\n",
       "           [ 1.4657,  1.4657,  1.4657,  ...,  1.6408,  1.6408,  1.6758],\n",
       "           ...,\n",
       "           [ 1.3782,  1.3957,  1.3957,  ...,  1.5007,  1.0105,  0.9405],\n",
       "           [ 1.3957,  1.3782,  1.3431,  ...,  0.6779,  1.0630,  1.2906],\n",
       "           [ 1.3782,  1.3431,  1.2906,  ...,  0.2927,  1.3081,  1.2906]],\n",
       " \n",
       "          [[ 1.6465,  1.6814,  1.7163,  ...,  1.8383,  1.7860,  1.8383],\n",
       "           [ 1.6465,  1.6814,  1.7163,  ...,  1.8557,  1.8383,  1.8731],\n",
       "           [ 1.6814,  1.6814,  1.6814,  ...,  1.8557,  1.8557,  1.8905],\n",
       "           ...,\n",
       "           [ 1.5594,  1.5768,  1.5768,  ...,  1.9254,  1.4200,  1.3328],\n",
       "           [ 1.5768,  1.5594,  1.5420,  ...,  1.1237,  1.4897,  1.6988],\n",
       "           [ 1.5594,  1.5420,  1.4897,  ...,  0.7402,  1.7163,  1.6988]]],\n",
       " \n",
       " \n",
       "         [[[ 1.8208,  1.8208,  1.8208,  ...,  1.7009,  1.7180,  1.7694],\n",
       "           [ 1.8208,  1.8208,  1.8208,  ...,  1.7009,  1.7180,  1.7694],\n",
       "           [ 1.8208,  1.8208,  1.8208,  ...,  1.7009,  1.7180,  1.7694],\n",
       "           ...,\n",
       "           [-1.9638, -1.9638, -1.9638,  ...,  1.7352,  1.7180,  1.7523],\n",
       "           [-1.9638, -1.9638, -1.9638,  ...,  1.7865,  1.7694,  1.7694],\n",
       "           [-1.9638, -1.9638, -1.9638,  ...,  1.7865,  1.7694,  1.7523]],\n",
       " \n",
       "          [[ 1.9909,  1.9909,  1.9909,  ...,  1.8158,  1.8158,  1.9384],\n",
       "           [ 1.9909,  1.9909,  1.9909,  ...,  1.8158,  1.8158,  1.9384],\n",
       "           [ 1.9909,  1.9909,  1.9909,  ...,  1.8158,  1.8158,  1.9384],\n",
       "           ...,\n",
       "           [-1.8782, -1.8782, -1.8782,  ...,  1.9209,  1.9384,  1.9384],\n",
       "           [-1.8782, -1.8782, -1.8782,  ...,  1.9909,  1.9734,  1.9734],\n",
       "           [-1.8782, -1.8782, -1.8782,  ...,  1.9734,  1.9734,  1.9909]],\n",
       " \n",
       "          [[ 2.2043,  2.2043,  2.2043,  ...,  2.0823,  2.0997,  2.1520],\n",
       "           [ 2.2043,  2.2043,  2.2043,  ...,  2.0823,  2.0997,  2.1520],\n",
       "           [ 2.2043,  2.2043,  2.2043,  ...,  2.0823,  2.0997,  2.1520],\n",
       "           ...,\n",
       "           [-1.6476, -1.6476, -1.6476,  ...,  2.1520,  2.1520,  2.1694],\n",
       "           [-1.6476, -1.6476, -1.6476,  ...,  2.2043,  2.2043,  2.2043],\n",
       "           [-1.6476, -1.6476, -1.6476,  ...,  2.2043,  2.2043,  2.2043]]],\n",
       " \n",
       " \n",
       "         [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
       "           [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
       "           [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
       "           ...,\n",
       "           [ 0.1597,  0.0741, -0.0116,  ...,  2.2489,  2.2489,  2.2489],\n",
       "           [ 0.1768,  0.0912, -0.0116,  ...,  2.2489,  2.2489,  2.2489],\n",
       "           [ 0.1939,  0.1254, -0.0458,  ...,  2.2489,  2.2489,  2.2489]],\n",
       " \n",
       "          [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
       "           [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
       "           [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
       "           ...,\n",
       "           [ 0.3277,  0.3102,  0.3627,  ...,  2.4286,  2.4286,  2.4286],\n",
       "           [ 0.3277,  0.3277,  0.3627,  ...,  2.4286,  2.4286,  2.4286],\n",
       "           [ 0.3452,  0.3277,  0.3277,  ...,  2.4286,  2.4286,  2.4286]],\n",
       " \n",
       "          [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
       "           [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
       "           [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
       "           ...,\n",
       "           [-0.3055, -0.3578, -0.4101,  ...,  2.6400,  2.6400,  2.6400],\n",
       "           [-0.2881, -0.3230, -0.3927,  ...,  2.6400,  2.6400,  2.6400],\n",
       "           [-0.2358, -0.2881, -0.3753,  ...,  2.6400,  2.6400,  2.6400]]]]),\n",
       " tensor([2, 1, 0, 2, 0, 0, 1, 2, 2, 0, 0, 1, 4, 0, 2, 1, 1, 1, 2, 2, 2, 2, 2, 0,\n",
       "         2, 1, 1, 1, 4, 1, 0, 0])]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 800, 'val': 200}\n"
     ]
    }
   ],
   "source": [
    "dataloaders = {'train': train_loader, 'val': test_loader}\n",
    "dataset_sizes = {'train': len(train_dataset), 'val': len(test_dataset)}\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[ 0.7419,  0.8618,  0.9474,  ...,  0.8447,  0.8447,  0.8447],\n",
       "           [ 0.6734,  0.8961,  0.9817,  ...,  0.8447,  0.8447,  0.8447],\n",
       "           [ 0.6906,  0.9474,  1.0673,  ...,  0.8447,  0.8447,  0.8447],\n",
       "           ...,\n",
       "           [ 0.8447,  0.8447,  0.8447,  ...,  0.8447,  0.8447,  0.8447],\n",
       "           [ 0.8447,  0.8447,  0.8447,  ...,  0.8447,  0.8447,  0.8447],\n",
       "           [ 0.8447,  0.8447,  0.8447,  ...,  0.8447,  0.8447,  0.8447]],\n",
       " \n",
       "          [[ 0.7129,  0.9405,  1.0455,  ...,  2.0434,  2.0434,  2.0434],\n",
       "           [ 0.6604,  0.9755,  1.0630,  ...,  2.0434,  2.0434,  2.0434],\n",
       "           [ 0.6429,  1.0455,  1.2031,  ...,  2.0434,  2.0434,  2.0434],\n",
       "           ...,\n",
       "           [ 2.0434,  2.0434,  2.0434,  ...,  2.0434,  2.0434,  2.0434],\n",
       "           [ 2.0434,  2.0434,  2.0434,  ...,  2.0434,  2.0434,  2.0434],\n",
       "           [ 2.0434,  2.0434,  2.0434,  ...,  2.0434,  2.0434,  2.0434]],\n",
       " \n",
       "          [[-0.4973, -0.5670, -0.5147,  ..., -1.8044, -1.8044, -1.8044],\n",
       "           [-0.5321, -0.5147, -0.4973,  ..., -1.8044, -1.8044, -1.8044],\n",
       "           [-0.4798, -0.4798, -0.4973,  ..., -1.8044, -1.8044, -1.8044],\n",
       "           ...,\n",
       "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
       " \n",
       " \n",
       "         [[[ 2.2489,  2.2489,  2.2489,  ...,  0.9132,  0.9132,  0.8961],\n",
       "           [ 2.2489,  2.2489,  2.2489,  ...,  0.9132,  0.9132,  0.8961],\n",
       "           [ 2.2489,  2.2489,  2.2318,  ...,  0.9303,  0.9303,  0.9303],\n",
       "           ...,\n",
       "           [-2.1179, -2.1179, -2.1179,  ...,  2.2489,  2.2489,  2.2489],\n",
       "           [-2.1179, -2.1179, -2.1179,  ...,  2.2489,  2.2489,  2.2489],\n",
       "           [-2.1179, -2.1179, -2.1179,  ...,  2.2489,  2.2489,  2.2489]],\n",
       " \n",
       "          [[ 2.4286,  2.4286,  2.4286,  ...,  1.0805,  1.0805,  1.0630],\n",
       "           [ 2.4286,  2.4286,  2.4286,  ...,  1.0805,  1.0805,  1.0630],\n",
       "           [ 2.4286,  2.4286,  2.4111,  ...,  1.1506,  1.1506,  1.0980],\n",
       "           ...,\n",
       "           [-2.0357, -2.0357, -2.0357,  ...,  2.4286,  2.4286,  2.4286],\n",
       "           [-2.0357, -2.0357, -2.0357,  ...,  2.4286,  2.4286,  2.4286],\n",
       "           [-2.0357, -2.0357, -2.0357,  ...,  2.4286,  2.4286,  2.4286]],\n",
       " \n",
       "          [[ 2.6400,  2.6400,  2.6400,  ...,  1.2282,  1.2282,  1.2108],\n",
       "           [ 2.6400,  2.6226,  2.5877,  ...,  1.2108,  1.2108,  1.1934],\n",
       "           [ 2.6226,  2.5703,  2.5354,  ...,  1.2457,  1.2457,  1.2282],\n",
       "           ...,\n",
       "           [-1.8044, -1.8044, -1.8044,  ...,  2.6400,  2.6400,  2.6400],\n",
       "           [-1.8044, -1.8044, -1.8044,  ...,  2.6400,  2.6400,  2.6400],\n",
       "           [-1.8044, -1.8044, -1.8044,  ...,  2.6400,  2.6400,  2.6400]]],\n",
       " \n",
       " \n",
       "         [[[ 2.0948,  2.0777,  2.0948,  ...,  0.3481,  1.6838,  2.0948],\n",
       "           [ 2.0948,  2.0948,  2.0948,  ...,  0.7933,  1.8379,  1.8379],\n",
       "           [ 2.0948,  2.0948,  2.0948,  ...,  1.1358,  1.6667,  1.4269],\n",
       "           ...,\n",
       "           [ 2.0948,  2.0948,  2.0948,  ...,  2.0948,  2.0948,  2.0948],\n",
       "           [ 2.0948,  2.0948,  2.0948,  ...,  2.0948,  2.0948,  2.0948],\n",
       "           [ 2.0948,  2.0948,  2.0948,  ...,  2.0948,  2.0948,  2.0948]],\n",
       " \n",
       "          [[ 2.2360,  2.1835,  2.1485,  ..., -0.0749,  1.3256,  1.8333],\n",
       "           [ 2.2535,  2.2185,  2.1660,  ...,  0.4328,  1.5007,  1.5007],\n",
       "           [ 2.1835,  2.1835,  2.1835,  ...,  0.8004,  1.3256,  1.0980],\n",
       "           ...,\n",
       "           [ 0.5903,  0.5553,  0.5203,  ...,  0.5553,  0.4853,  0.5028],\n",
       "           [ 0.5903,  0.5903,  0.5903,  ...,  0.5378,  0.4853,  0.4503],\n",
       "           [ 0.5553,  0.5553,  0.5903,  ...,  0.5203,  0.4678,  0.4328]],\n",
       " \n",
       "          [[ 2.4657,  2.4831,  2.4483,  ...,  0.3045,  1.6640,  2.1171],\n",
       "           [ 2.4657,  2.4483,  2.4308,  ...,  0.7925,  1.8208,  1.8208],\n",
       "           [ 2.4134,  2.4134,  2.4308,  ...,  1.1237,  1.6640,  1.4200],\n",
       "           ...,\n",
       "           [ 1.5942,  1.5768,  1.4722,  ...,  0.7751,  0.7054,  0.6879],\n",
       "           [ 1.5942,  1.5942,  1.5594,  ...,  0.7576,  0.7054,  0.6705],\n",
       "           [ 1.5768,  1.5768,  1.5594,  ...,  0.7402,  0.6879,  0.6531]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.2282,  0.3309,  0.5536,  ...,  1.8893,  1.9407,  2.0263],\n",
       "           [ 0.5707,  0.7248,  0.8789,  ...,  1.9235,  2.0263,  2.0605],\n",
       "           [ 0.7762,  1.0502,  1.0673,  ...,  1.9920,  2.1462,  2.1119],\n",
       "           ...,\n",
       "           [-1.4500, -1.3815, -1.3987,  ...,  0.9303,  0.9474,  0.9646],\n",
       "           [-1.4329, -1.3473, -1.3987,  ...,  0.9303,  0.9474,  0.9646],\n",
       "           [-1.4329, -1.3473, -1.4158,  ...,  0.9303,  0.9474,  0.9646]],\n",
       " \n",
       "          [[-0.1450, -0.0749,  0.1176,  ...,  1.6758,  1.6583,  1.6933],\n",
       "           [ 0.1877,  0.2927,  0.4503,  ...,  1.7458,  1.7633,  1.7283],\n",
       "           [ 0.3978,  0.6254,  0.6604,  ...,  1.7458,  1.8158,  1.7283],\n",
       "           ...,\n",
       "           [ 0.5378,  0.6078,  0.5903,  ..., -1.0378, -1.0028, -0.9853],\n",
       "           [ 0.5553,  0.6254,  0.5903,  ..., -1.0378, -1.0028, -0.9853],\n",
       "           [ 0.5553,  0.6254,  0.5728,  ..., -1.0378, -1.0028, -0.9853]],\n",
       " \n",
       "          [[-0.5147, -0.4973, -0.3578,  ...,  1.2980,  1.1759,  1.0888],\n",
       "           [-0.1661, -0.0964,  0.0082,  ...,  1.3328,  1.2805,  1.1237],\n",
       "           [ 0.0431,  0.2522,  0.1476,  ...,  1.3677,  1.3154,  1.1585],\n",
       "           ...,\n",
       "           [ 0.2871,  0.3568,  0.3393,  ..., -1.2990, -1.2467, -1.2467],\n",
       "           [ 0.3045,  0.3393,  0.3393,  ..., -1.2990, -1.2467, -1.2467],\n",
       "           [ 0.3045,  0.3393,  0.3219,  ..., -1.2990, -1.2467, -1.2467]]],\n",
       " \n",
       " \n",
       "         [[[ 1.7009,  1.7009,  1.7009,  ...,  1.6838,  1.6838,  1.6838],\n",
       "           [ 1.7009,  1.7009,  1.7009,  ...,  1.6838,  1.6838,  1.6838],\n",
       "           [ 1.7009,  1.7009,  1.7009,  ...,  1.6838,  1.6838,  1.6838],\n",
       "           ...,\n",
       "           [ 1.4098,  1.3927,  1.3927,  ...,  1.5639,  1.5468,  1.5468],\n",
       "           [ 1.4098,  1.3927,  1.3927,  ...,  1.5639,  1.5639,  1.5639],\n",
       "           [ 1.4098,  1.3927,  1.3927,  ...,  1.5639,  1.5639,  1.5639]],\n",
       " \n",
       "          [[ 1.6933,  1.6933,  1.6933,  ...,  1.6408,  1.6408,  1.6408],\n",
       "           [ 1.6933,  1.6933,  1.6933,  ...,  1.6408,  1.6408,  1.6408],\n",
       "           [ 1.6933,  1.6933,  1.6933,  ...,  1.6408,  1.6408,  1.6408],\n",
       "           ...,\n",
       "           [ 1.4832,  1.5007,  1.5007,  ...,  1.6583,  1.6408,  1.6583],\n",
       "           [ 1.4832,  1.5007,  1.5007,  ...,  1.6758,  1.6758,  1.7108],\n",
       "           [ 1.4832,  1.5007,  1.5007,  ...,  1.6758,  1.6758,  1.7108]],\n",
       " \n",
       "          [[ 1.9080,  1.9080,  1.9080,  ...,  1.8905,  1.8905,  1.8905],\n",
       "           [ 1.9080,  1.9080,  1.9080,  ...,  1.8905,  1.8905,  1.8905],\n",
       "           [ 1.9080,  1.9080,  1.9080,  ...,  1.8905,  1.8905,  1.8905],\n",
       "           ...,\n",
       "           [ 1.7860,  1.7511,  1.7511,  ...,  1.8034,  1.7860,  1.7860],\n",
       "           [ 1.7860,  1.7511,  1.7511,  ...,  1.8034,  1.8034,  1.7860],\n",
       "           [ 1.7860,  1.7511,  1.7511,  ...,  1.8034,  1.8034,  1.7860]]],\n",
       " \n",
       " \n",
       "         [[[-0.1828, -0.0458,  0.0741,  ...,  0.9303,  0.9474,  0.9474],\n",
       "           [-0.1828, -0.0458,  0.0741,  ...,  0.9303,  0.9474,  0.9474],\n",
       "           [-0.1828, -0.0629,  0.0741,  ...,  0.9303,  0.9474,  0.9474],\n",
       "           ...,\n",
       "           [-0.6281, -0.6281, -0.6281,  ...,  1.7180,  1.7180,  1.7180],\n",
       "           [-0.6281, -0.6281, -0.6281,  ...,  1.7180,  1.7180,  1.7180],\n",
       "           [-0.6281, -0.6281, -0.6281,  ...,  1.6838,  1.6495,  1.6495]],\n",
       " \n",
       "          [[-0.2850, -0.1450, -0.0224,  ...,  0.8704,  0.8880,  0.8880],\n",
       "           [-0.2850, -0.1450, -0.0224,  ...,  0.8704,  0.8880,  0.8880],\n",
       "           [-0.2850, -0.1625, -0.0224,  ...,  0.8704,  0.8880,  0.8880],\n",
       "           ...,\n",
       "           [-0.7402, -0.7402, -0.7402,  ...,  1.7108,  1.7283,  1.7283],\n",
       "           [-0.7752, -0.7752, -0.7402,  ...,  1.7283,  1.7283,  1.7283],\n",
       "           [-0.7752, -0.7752, -0.7402,  ...,  1.6408,  1.6408,  1.6057]],\n",
       " \n",
       "          [[-0.0092,  0.1651,  0.2871,  ...,  1.1411,  1.1759,  1.1759],\n",
       "           [-0.0092,  0.1651,  0.2871,  ...,  1.1411,  1.1759,  1.1759],\n",
       "           [-0.0267,  0.1476,  0.2871,  ...,  1.1411,  1.1759,  1.1759],\n",
       "           ...,\n",
       "           [-0.4450, -0.4450, -0.4450,  ...,  1.8905,  1.9428,  1.9428],\n",
       "           [-0.4624, -0.4624, -0.4450,  ...,  1.8731,  1.8905,  1.8731],\n",
       "           [-0.4624, -0.4624, -0.4450,  ...,  1.8208,  1.7860,  1.7685]]]]),\n",
       " tensor([1, 3, 3, 1, 0, 2, 4, 2, 4, 2, 1, 2, 2, 1, 1, 1, 3, 0, 3, 3, 2, 3, 2, 3,\n",
       "         2, 4, 2, 0, 2, 0, 0, 1])]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataloaders['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels in dataloaders[phase]:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(torch.load(best_model_params_path, weights_only=True))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f'predicted: {values[0][preds[j]]}')\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.resnet18(weights='IMAGENET1K_V1')\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to ``nn.Linear(num_ftrs, len(class_names))``.\n",
    "model_ft.fc = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(num_ftrs, len(values[0]))\n",
    ")\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.CosineAnnealingLR(optimizer_ft, T_max=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False  # Freeze all layers initially\n",
    "for param in model_ft.fc.parameters():\n",
    "    param.requires_grad = True  # Unfreeze only the final layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 2.9522 Acc: 0.2162\n",
      "val Loss: 2.0977 Acc: 0.2000\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 2.4152 Acc: 0.2725\n",
      "val Loss: 2.9997 Acc: 0.2300\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 2.6527 Acc: 0.2687\n",
      "val Loss: 2.3263 Acc: 0.2850\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 2.6435 Acc: 0.3050\n",
      "val Loss: 3.2492 Acc: 0.2100\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_ft \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_ft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_ft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_lr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[47], line 26\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     23\u001b[0m running_corrects \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Iterate over data.\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[43mphase\u001b[49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[37], line 21\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     19\u001b[0m file_number \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_numbers[idx]\n\u001b[1;32m     20\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_number\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m06d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m transformed_img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m attributes \u001b[38;5;241m=\u001b[39m convert_attributes_to_tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_csv\u001b[38;5;241m.\u001b[39mloc[idx])\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m transformed_img, attributes[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torchvision/transforms/transforms.py:1278\u001b[0m, in \u001b[0;36mColorJitter.forward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     img \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39madjust_contrast(img, contrast_factor)\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m fn_id \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m saturation_factor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1278\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madjust_saturation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaturation_factor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m fn_id \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m hue_factor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1280\u001b[0m     img \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39madjust_hue(img, hue_factor)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torchvision/transforms/functional.py:914\u001b[0m, in \u001b[0;36madjust_saturation\u001b[0;34m(img, saturation_factor)\u001b[0m\n\u001b[1;32m    912\u001b[0m     _log_api_usage_once(adjust_saturation)\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_pil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madjust_saturation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaturation_factor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F_t\u001b[38;5;241m.\u001b[39madjust_saturation(img, saturation_factor)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torchvision/transforms/_functional_pil.py:92\u001b[0m, in \u001b[0;36madjust_saturation\u001b[0;34m(img, saturation_factor)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_pil_image(img):\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg should be PIL Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(img)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 92\u001b[0m enhancer \u001b[38;5;241m=\u001b[39m \u001b[43mImageEnhance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m img \u001b[38;5;241m=\u001b[39m enhancer\u001b[38;5;241m.\u001b[39menhance(saturation_factor)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/PIL/ImageEnhance.py:54\u001b[0m, in \u001b[0;36mColor.__init__\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m image\u001b[38;5;241m.\u001b[39mgetbands():\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLA\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdegenerate \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate_mode\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconvert(image\u001b[38;5;241m.\u001b[39mmode)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/PIL/Image.py:1062\u001b[0m, in \u001b[0;36mImage.convert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m   1059\u001b[0m     dither \u001b[38;5;241m=\u001b[39m Dither\u001b[38;5;241m.\u001b[39mFLOYDSTEINBERG\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1062\u001b[0m     im \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdither\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         \u001b[38;5;66;03m# normalize source image and try again\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
